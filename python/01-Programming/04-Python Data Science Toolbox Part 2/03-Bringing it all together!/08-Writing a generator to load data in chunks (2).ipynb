{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing a generator to load data in chunks (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXERCISE:\n",
    "In the previous exercise, you processed a file line by line for a given number of lines. What if, however, you want to do this for the entire file?\n",
    "\n",
    "In this case, it would be useful to use <strong>generators</strong>. Generators allow users to <a href=\"http://www.blog.pythonlibrary.org/2014/01/27/python-201-an-intro-to-generators/\" target=\"_blank\"><em>lazily evaluate</em> data</a>. \n",
    "This concept of <em>lazy evaluation</em> is useful when you have to deal with very large datasets because it lets you generate values in an efficient manner by <em>yielding</em> only chunks of data at a time instead of the whole thing at once.\n",
    "\n",
    "In this exercise, you will define a generator function <code>read_large_file()</code> that produces a generator object which yields a single line from a file each time <code>next()</code> is called on it. The csv file <code>'world_dev_ind.csv'</code> is in your current directory for your use.\n",
    "\n",
    "Note that when you open a connection to a file, the resulting file object is already a generator! So out in the wild, you won't have to explicitly create generator objects in cases such as this. However, for pedagogical reasons, we are having you practice how to do this here with the <code>read_large_file()</code> function. Go for it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### INSTRUCTIONS:\n",
    "* In the function <code>read_large_file()</code>, read a line from <code>file_object</code> by using the method <code>readline()</code>. Assign the result to <code>data</code>.\n",
    "* In the function <code>read_large_file()</code>, <code>yield</code> the line read from the file <code>data</code>.\n",
    "* In the context manager, create a generator object <code>gen_file</code> by calling your generator function <code>read_large_file()</code> and passing <code>file</code> to it.\n",
    "* Print the first three lines produced by the generator object <code>gen_file</code> using <code>next()</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SCRIPT.PY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define read_large_file()\n",
    "def read_large_file(file_object):\n",
    "    \"\"\"A generator function to read a large file lazily.\"\"\"\n",
    "\n",
    "    # Loop indefinitely until the end of the file\n",
    "    while True:\n",
    "\n",
    "        # Read a line from the file: data\n",
    "        data = ____\n",
    "\n",
    "        # Break if this is the end of the file\n",
    "        if not data:\n",
    "            break\n",
    "\n",
    "        # Yield the line of data\n",
    "        \n",
    "        \n",
    "# Open a connection to the file\n",
    "with open('world_dev_ind.csv') as file:\n",
    "\n",
    "    # Create a generator object for the file: gen_file\n",
    "    gen_file = ____\n",
    "\n",
    "    # Print the first three lines of the file\n",
    "    print(____)\n",
    "    print(____)\n",
    "    print(____)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
