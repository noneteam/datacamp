{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding files that match a pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXERCISE:\n",
    "You're now going to practice using the <code>glob</code> module to find all csv files in the workspace. In the next exercise, you'll programmatically load them into DataFrames.\n",
    "\n",
    "As Dan showed you in the video, the <code>glob</code> module has a function called <code>glob</code> that takes a pattern and returns a list of the files in the working directory that match that pattern.\n",
    "\n",
    "For example, if you know the pattern is <code>part_</code> <code>single digit number</code> <code>.csv</code>, you can write the pattern as <code>'part_?.csv'</code> (which would match <code>part_1.csv</code>, <code>part_2.csv</code>, <code>part_3.csv</code>, etc.)\n",
    "\n",
    "Similarly, you can find all <code>.csv</code> files with <code>'*.csv'</code>, or all parts with <code>'part_*'</code>. The <code>?</code> wildcard represents any 1 character, and the <code>*</code> wildcard represents any number of characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### INSTRUCTIONS:\n",
    "* Import the <code>glob</code> module along with <code>pandas</code> (as its usual alias <code>pd</code>).\n",
    "* Write a pattern to match all <code>.csv</code> files.\n",
    "* Save all files that match the pattern using the <code>glob()</code> function within the <code>glob</code> module. That is, by using <code>glob.glob()</code>.\n",
    "* Print the list of file names. This has been done for you.\n",
    "* Read the second file in <code>csv_files</code> (i.e., index <code>1</code>) into a DataFrame called <code>csv2</code>.\n",
    "* Hit 'Submit Answer' to print the head of <code>csv2</code>. Does it look familiar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SCRIPT.PY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['uber-raw-data-2014_04.csv', 'uber-raw-data-2014_06.csv', 'uber-raw-data-2014_05.csv']\n",
      "          Date/Time      Lat      Lon    Base\n",
      "0  6/1/2014 0:00:00  40.7293 -73.9920  B02512\n",
      "1  6/1/2014 0:01:00  40.7131 -74.0097  B02512\n",
      "2  6/1/2014 0:04:00  40.3461 -74.6610  B02512\n",
      "3  6/1/2014 0:04:00  40.7555 -73.9833  B02512\n",
      "4  6/1/2014 0:07:00  40.6880 -74.1831  B02512\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Write the pattern: pattern\n",
    "pattern = \"uber-raw-data-2014_0?.csv\"#'*.csv'\n",
    "\n",
    "# Save all file matches: csv_files\n",
    "csv_files = glob.glob(pattern)\n",
    "\n",
    "# Print the file names\n",
    "print(csv_files)\n",
    "\n",
    "# Load the second file into a DataFrame: csv2\n",
    "csv2 = pd.read_csv(csv_files[1])\n",
    "\n",
    "# Print the head of csv2\n",
    "print(csv2.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
