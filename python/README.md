# 01-Python Programming
Discover important data structures like dictionaries and DataFrames, visualize real world data with matplotlib, and learn the art of writing your own Python functions.

## 01-01-Intro to Python for Data Science
Python is a general-purpose programming language that is becoming more and more popular for doing data science. Companies worldwide are using Python to harvest insights from their data and get a competitive edge. Unlike any other Python tutorial, this course focuses on Python specifically for data science. In our Intro to Python class, you will learn about powerful ways to store and manipulate data as well as cool data science tools to start your own analyses. Enter DataCamp’s online Python curriculum.

#### 01-01-01-[Python Basics](</python/01-Programming/01-Intro to Python for Data Science/01-Python Basics>)
An introduction to the basic concepts of Python. Learn how to use Python both interactively and through a script. Create your first variables and acquaint yourself with Python's basic data types.

* Hello Python!
* The Python Interface
* When to use Python?
* Any comments?
* Python as a calculator
* Variables & Types
* Variable Assignment
* Calculations with variables
* Other variable types
* Guess the type
* Operations with other types
* Type conversion
* Can Python handle everything?

#### 01-01-02-[Python Lists](</python/01-Programming/01-Intro to Python for Data Science/02-Python Lists>)
Learn to store, access and manipulate data in lists: the first step towards efficiently working with huge amounts of data.

* Lists, what are they?
* Create a list
* Create list with different types
* Select the valid list
* List of lists
* Subsetting lists
* Subset and conquer
* Subset and calculate
* Slicing and dicing
* Slicing and dicing (2)
* Subsetting lists of lists
* List Manipulation
* Replace list elements
* Extend a list
* Delete list elements
* Inner workings of lists

#### 01-01-03-[Functions and Packages](</python/01-Programming/01-Intro to Python for Data Science/03-Functions and Packages>)
To leverage the code that brilliant Python developers have written, you'll learn about using functions, methods and packages. This will help you to reduce the amount of code you need to solve challenging problems!

* Functions
* Familiar functions
* Help!
* Multiple arguments
* Methods
* String Methods
* List Methods
* List Methods (2)
* Packages
* Import package
* Selective import
* Different ways of importing

#### 01-01-04-[NumPy](</python/01-Programming/01-Intro to Python for Data Science/04-NumPy>)
NumPy is a Python package to efficiently do data science. Learn to work with the NumPy array, a faster and more powerful alternative to the list, and take your first steps in data exploration.

* NumPy
* Your First NumPy Array
* Baseball players' height
* Baseball player's BMI
* Lightweight baseball players
* NumPy Side Effects
* Subsetting NumPy Arrays
* 2D NumPy Arrays
* Your First 2D NumPy Array
* Baseball data in 2D form
* Subsetting 2D NumPy Arrays
* 2D Arithmetic
* NumPy: Basic Statistics
* Average versus median
* Explore the baseball data
* Blend it all together

## 01-02-Intermediate Python for Data Science
The intermediate python course is crucial to your data science curriculum. Learn to visualize real data with matplotlib's functions and get to know new data structures such as the dictionary and the Pandas DataFrame. After covering key concepts such as boolean logic, control flow and loops in Python, you're ready to blend together everything you've learned to solve a case study using hacker statistics.

#### 01-02-01-[Matplotlib](</python/01-Programming/02-Intermediate Python for Data Science/01-Matplotlib>)
Data Visualization is a key skill for aspiring data scientists. Matplotlib makes it easy to create meaningful and insightful plots. In this chapter, you will learn to build various types of plots and to customize them to make them more visually appealing and interpretable.

* Basic plots with matplotlib
* Line plot (1)
* Line Plot (2): Interpretation
* Line plot (3)
* Scatter Plot (1)
* Scatter plot (2)
* Histograms
* Build a histogram (1)
* Build a histogram (2): bins
* Build a histogram (3): compare
* Choose the right plot (1)
* Choose the right plot (2)
* Customization
* Labels
* Ticks
* Sizes
* Colors
* Additional Customizations
* Interpretation

#### 01-02-02-[Dictionaries & Pandas](</python/01-Programming/02-Intermediate Python for Data Science/02-Dictionaries & Pandas>)
Learn about the dictionary, an alternative to the Python list, and the Pandas DataFrame, the de facto standard to work with tabular data in Python. You will get hands-on practice with creating, manipulating and accessing the information you need from these data structures.

* Dictionaries, Part 1
* Motivation for dictionaries
* Create dictionary
* Access dictionary
* Dictionaries, Part 2
* Dictionary Manipulation (1)
* Dictionary Manipulation (2)
* Dictionariception
* Pandas, Part 1
* Dictionary to DataFrame (1)
* Dictionary to DataFrame (2)
* CSV to DataFrame (1)
* CSV to DataFrame (2)
* Pandas, Part 2
* Square Brackets (1)
* Square Brackets (2)
* loc and iloc (1)
* loc and iloc (2)
* loc and iloc (3)

#### 01-02-03-[Logic, Control Flow and Filtering](</python/01-Programming/02-Intermediate Python for Data Science/03-Logic, Control Flow and Filtering>)
Boolean logic is the foundation of decision-making in your Python programs. Learn about different comparison operators, how you can combine them with boolean operators and how to use the boolean outcomes in control structures. You'll also learn to filter data from Pandas DataFrames using logic.

* Comparison Operators
* Equality
* Greater and less than
* Compare arrays
* Boolean Operators
* and, or, not (1)
* and, or, not (2)
* Boolean operators with Numpy
* if, elif, else
* Warmup
* if
* Add else
* Customize further: elif
* Filtering Pandas DataFrame
* Driving right (1)
* Driving right (2)
* Cars per capita (1)
* Cars per capita (2)

#### 01-02-04-[Loops](</python/01-Programming/02-Intermediate Python for Data Science/04-Loops>)
There are several techniques to repeatedly execute Python code. While loops are like repeated if statements; the for loop is there to iterate over all kinds of data structures. Learn all about them in this chapter.

* while loop
* while: warming up
* Basic while loop
* Add conditionals
* for loop
* Loop over a list
* Indexes and values (1)
* Indexes and values (2)
* Loop over list of lists
* Looping Data Structures, Part 1
* Loop over dictionary
* Loop over Numpy array
* Looping Data Structures, Part 2
* Loop over DataFrame (1)
* Loop over DataFrame (2)
* Add column (1)
* Add column (2)

#### 01-02-05-[Case Study: Hacker Statistics](</python/01-Programming/02-Intermediate Python for Data Science/05-Case Study: Hacker Statistics>)
This chapter blends together everything you've learned up to now. You will use hacker statistics to calculate your chances of winning a bet. Use random number generators, loops and matplotlib to get the competitive edge!

* Random Numbers
* Random float
* Roll the dice
* Determine your next move
* Random Walk
* The next step
* How low can you go?
* Visualize the walk
* Distribution
* Simulate multiple walks
* Visualize all walks
* Implement clumsiness
* Plot the distribution
* Calculate the odds

## 01-03-Python Data Science Toolbox (Part 1)
It's now time to push forward and develop your Python chops even further. There are lots and lots of fantastic functions in Python and its library ecosystem. However, as a Data Scientist, you'll constantly need to write your own functions to solve problems that are dictated by your data. The art of function writing is what you'll learn in this first Python Data Science toolbox course. You'll come out of this course being able to write your very own custom functions, complete with multiple parameters and multiple return values, along with default arguments and variable-length arguments. You'll gain insight into scoping in Python and be able to write lambda functions and handle errors in your very own function writing practice. On top of this, you'll wrap up each Chapter by diving into using your acquired skills to write functions that analyze twitter DataFrames and are generalizable to broader Data Science contexts.

#### 01-03-01-[Writing your own functions](</python/01-Programming/03-Python Data Science Toolbox Part 1/01-Writing your own functions>)
Here you will learn how to write your very own functions. In this Chapter, you'll learn how to write simple functions, as well as functions that accept multiple arguments and return multiple values. You'll also have the opportunity to apply these newfound skills to questions that commonly arise in Data Science contexts.

* User-defined functions
* Strings in Python
* Recapping built-in functions
* Write a simple function
* Single-parameter functions
* Functions that return single values
* Multiple parameters and return values
* Functions with multiple parameters
* A brief introduction to tuples
* Functions that return multiple values
* Bringing it all together
* Bringing it all together (1)
* Bringing it all together (2)
* Congratulations!

#### 01-03-02-[Default arguments, variable-length arguments and scope](</python/01-Programming/03-Python Data Science Toolbox Part 1/02-Default arguments, variable-length arguments and scope>)
In this chapter, you'll learn to write functions with default arguments, so that the user doesn't always need to specify them, and variable-length arguments, so that they can pass to your functions an arbitrary number of arguments. These are both incredibly useful tools! You'll also learn about the essential concept of scope. Enjoy!

* Scope and user-defined functions
* Pop quiz on understanding scope
* The keyword global
* Python's built-in scope
* Nested functions
* Nested Functions I
* Nested Functions II
* The keyword nonlocal and nested functions
* Default and flexible arguments
* Functions with one default argument
* Functions with multiple default arguments
* Functions with variable-length arguments (*args)
* Functions with variable-length keyword arguments (**kwargs)
* Bringing it all together
* Bringing it all together (1)
* Bringing it all together (2)

#### 01-03-03-[Lambda functions and error-handling](</python/01-Programming/03-Python Data Science Toolbox Part 1/03-Lambda functions and error-handling>)
Herein, you'll learn about lambda functions, which allow you to write functions quickly and on-the-fly. You'll also get practice at handling errors that your functions, at some point, will inevitably throw. You'll wrap up once again applying these skills to Data Science questions.

* Lambda functions
* Pop quiz on lambda functions
* Writing a lambda function you already know
* Map() and lambda functions
* Filter() and lambda functions
* Reduce() and lambda functions
* Introduction to error handling
* Pop quiz about errors
* Error handling with try-except
* Error handling by raising an error
* Bringing it all together
* Bringing it all together (1)
* Bringing it all together (2)
* Bringing it all together (3)
* Bringing it all together: testing your error handling skills
* Congratulations!

## 01-04-Python Data Science Toolbox (Part 2)
In this second course in the Python Data Science Toolbox, you'll continue to build your Python Data Science skills. First you'll enter the wonderful world of iterators, objects that you have already encountered in the context of for loops without having necessarily known it. You'll then learn about list comprehensions, which are extremely handy tools that form a basic component in the toolbox of all modern Data Scientists working in Python. You'll end the course by working through a case study in which you'll apply all of the techniques you learned both in this course as well as the prequel. If you're looking to make it as a Pythonista Data Science ninja, you have come to the right place.

#### 01-04-01-[Using iterators in PythonLand](</python/01-Programming/04-Python Data Science Toolbox Part 2/01-Using iterators in PythonLand>)
Here, you'll learn all about iterators and iterables, which you have already worked with before when writing for loops! You'll learn about some very useful functions that will allow you to effectively work with iterators and finish the chapter with a use case that is pertinent to the world of Data Science - dealing with large amounts of data - in this case, data from Twitter that you will load in chunks using iterators!

* Introduction to iterators
* Iterators vs Iterables
* Iterating over iterables (1)
* Iterating over iterables (2)
* Iterators as function arguments
* Playing with iterators
* Using enumerate
* Using zip
* Using * and zip to 'unzip'
* Using iterators to load large files into memory
* Processing large amounts of Twitter data
* Extracting information for large amounts of Twitter data
* Congratulations!!

#### 01-04-02-[List comprehensions and generators](</python/01-Programming/04-Python Data Science Toolbox Part 2/02-List comprehensions and generators>)
In this chapter, you'll build on your knowledge of iterators and be introduced to list comprehensions, which allow you to create complicated lists and lists of lists in one line of code! List comprehensions can dramatically simplify your code and make it more efficient, and will become a vital part of your Python Data Science toolbox. You'll then learn about generators, which are extremely helpful when working with large sequences of data that you may not want to store in memory but instead generate on the fly. 

* List comprehensions
* Write a basic list comprehension
* List comprehension over iterables
* Writing list comprehensions
* Nested list comprehensions
* Advanced comprehensions
* Using conditionals in comprehensions (1)
* Using conditionals in comprehensions (2)
* Dict comprehensions
* Introduction to generator expressions
* List comprehensions vs generators
* Write your own generator expressions
* Changing the output in generator expressions
* Build a generator
* Wrapping up comprehensions and generators.
* List comprehensions for time-stamped data
* Conditional list comprehensions for time-stamped data

#### 01-04-03-[Bringing it all together!](</python/01-Programming/04-Python Data Science Toolbox Part 2/03-Bringing it all together!>)
This chapter will allow you to apply your newly acquired skills towards wrangling and extracting meaningful information from a real-world dataset - the World Bank's World Development Indicators dataset! You'll have the chance to write your own functions and list comprehensions as you work with iterators and generators and solidify your Python Data Science chops. Enjoy! 

* Welcome to the case study!
* Dictionaries for data science
* Writing a function to help you
* Using a list comprehension
* Turning this all into a DataFrame
* Using Python generators for streaming data
* Processing data in chunks (1)
* Writing a generator to load data in chunks (2)
* Writing a generator to load data in chunks (3)
* Using pandas' read_csv iterator for streaming data
* Writing an iterator to load data in chunks (1)
* Writing an iterator to load data in chunks (2)
* Writing an iterator to load data in chunks (3)
* Writing an iterator to load data in chunks (4)
* Writing an iterator to load data in chunks (5)
* Final thoughts

## 01-05-Data Types for Data Science
Have you got your basic Python programming chops down for Data Science but are yearning for more? Then this is the course for you. Herein, you'll consolidate and practice your knowledge of lists, dictionaries, tuples, sets, and date times. You'll see their relevance in working with lots of real data and how to leverage several of them in concert to solve multistep problems, including an extended case study using Chicago metropolitan area transit data. You'll also learn how to use many of the objects in the Python Collections module, which will allow you to store and manipulate your data for a variety of Data Scientific purposes. After taking this course, you'll be ready to tackle many Data Science challenges Pythonically.

#### 01-05-01-[Fundamental data types](</python/01-Programming/05-Data Types for Data Science/01-Fundamental data types>)
This chapter will introduce you to the fundamental Python data types - lists, sets, and tuples. These data containers are critical as they provide the basis for storing and looping over ordered data. To make things interesting, you'll apply what you learn about these types to answer questions about the New York Baby Names dataset!

* Introduction and lists
* Manipulating lists for fun and profit
* Looping over lists
* Meet the Tuples
* Data type usage
* Using and unpacking tuples
* Making tuples by accident
* Sets for unordered and unique data
* Finding all the data and the overlapping data between sets
* Determining set differences

#### 01-05-02-[Dictionaries - the root of Python](</python/01-Programming/05-Data Types for Data Science/02-Dictionaries - the root of Python>)
At the root of all things Python is a dictionary. Herein, you'll learn how to use them to safely handle data that can viewed in a variety of ways to answer even more questions about the New York Baby Names dataset. You'll explore how to loop through data in a dictionary, access nested data, add new data, and come to appreciate all of the wonderful capabilities of Python dictionaries.

* Using dictionaries
* Creating and looping through dictionaries
* Safely finding by key
* Dealing with nested data
* Altering dictionaries
* Adding and extending dictionaries
* Popping and deleting from dictionaries
* Pythonically using dictionaries
* Working with dictionaries more pythonically
* Checking dictionaries for data
* Working with CSV files
* Reading from a file using CSV reader
* Creating a dictionary from a file

#### 01-05-03-[Meet the collections module](</python/01-Programming/05-Data Types for Data Science/03-Meet the collections module>)
The collections module is part of Python's standard library and holds some more advanced data containers. You'll learn how to use the Counter, defaultdict, OrderedDict and namedtuple in the context of answering questions about the Chicago transit dataset. 

* Counting made easy
* Using Counter on lists
* Finding most common elements
* Dictionaries of unknown structure - Defaultdict
* Creating dictionaries of an unknown structure
* Safely appending to a key's value list
* Maintaining Dictionary Order with OrderedDict
* Working with OrderedDictionaries
* Powerful Ordered popping
* What do you mean I don't have any class? Namedtuple
* Creating namedtuples for storing data
* Leveraging attributes on namedtuples

#### 01-05-04-[Handling Dates and Times](</python/01-Programming/05-Data Types for Data Science/04-Handling Dates and Times>)
Handling times can seem daunting at time, but here, you'll dig in and learn how to create datetime objects, print them, look to the past and to the future. Additionally, you'll learn about some third party modules that can make all of this easier. You'll continue to use the Chicago Transit dataset to answer questions about transit times. 

* There and Back Again a DateTime Journey
* Strings to DateTimes
* Converting to a String
* Working with Datetime Components and current time
* Pieces of Time
* Creating DateTime Objects... Now
* Timezones
* Time Travel (Adding and Subtracting Time)
* Finding a time in the future and from the past
* Finding differences in DateTimes
* HELP! Libraries to make it easier
* Localizing time with pendulum
* Humanizing Differences with Pendulum

#### 01-05-05-[Answering Data Science Questions](</python/01-Programming/05-Data Types for Data Science/05-Answering Data Science Questions>)
Time for a case study to reinforce all of your learning so far! You'll use all the containers and data types you've learned about to answer several real world questions about a dataset containing information about crime in Chicago. Have fun!

* Counting within Date Ranges
* Reading your data with CSV Reader and Establishing your Data Containers
* Find the Months with the Highest Number of Crimes
* Transforming your Data Containers to Month and Location
* Find the Most Common Crimes by Location Type by Month in 2016
* Dictionaries with Time Windows for Keys
* Reading your Data with DictReader and Establishing your Data Containers
* Determine the Arrests by District by Year
* Unique Crimes by City Block
* Final thoughts

## 01-07-Introduction to Data Science in Python
Begin your journey into Data Science! Even if you've never written a line of code in your life, you'll be able to follow this course and witness the power of Python to perform Data Science. You'll use data to solve the mystery of Bayes, the kidnapped Golden Retriever, and along the way you'll become familiar with basic Python syntax and popular Data Science modules like Matplotlib (for charts and graphs) and Pandas (for tabular data).

#### 01-07-01-[Getting Started in Python](</python/01-Programming/07-Introduction to Data Science in Python/01-Getting Started in Python>)
Welcome to the wonderful world of Data Analysis in Python! In this chapter, you'll learn the basics of Python syntax, load your first Python modules, and use functions to get a suspect list for the kidnapping of Bayes, DataCamp's prize-winning Golden Retriever.

* Dive into Python
* Importing Python modules
* Correcting a broken import
* Creating variables
* Creating a float
* Creating strings
* Correcting string errors
* Valid variable names
* Fun with functions
* Load a DataFrame
* Correcting a function error
* Snooping for suspects

#### 01-07-02-[Loading Data in pandas](</python/01-Programming/07-Introduction to Data Science in Python/02-Loading Data in pandas>)
In this chapter, you'll learn a powerful Python libary: pandas. Pandas lets you read, modify, and search tabular datasets (like spreadsheets and database tables). You'll examine credit card records for the suspects and see if any of them made suspicious purchases.

* What is pandas?
* Loading a DataFrame
* Inspecting a DataFrame
* Selecting columns
* Two methods for selecting columns
* Correcting column selection errors
* More column selection mistakes
* Selecting rows with logic
* Logical testing
* Selecting missing puppies
* Narrowing the list of suspects

#### 01-07-03-[Plotting Data with matplotlib](</python/01-Programming/07-Introduction to Data Science in Python/03-Plotting Data with matplotlib>)
Get ready to visualize your data! You'll create line plots with another Python module: matplotlib. Using line plots, you'll analyze the letter frequencies from the ransom note and several handwriting samples to determine the kidnapper.

* Creating line plots
* Working hard
* Or hardly working?
* Adding text to plots
* Adding a legend
* Adding labels
* Adding floating text
* Styling graphs
* Tracking crime statistics
* Playing with styles
* Identifying Bayes' kidnapper

#### 01-07-04-[Different Types of Plots](</python/01-Programming/07-Introduction to Data Science in Python/04-Different Types of Plots>)
In this final chapter, you'll learn how to create three new plot types: scatter plots, bar plots, and histograms. You'll use these tools to locate where the kidnapper is hiding and rescue Bayes, the Golden Retriever.

* Making a scatter plot
* Charting cellphone data
* Modifying a scatterplot
* Making a bar chart
* Build a simple bar chart
* Where did the time go?
* Making a histogram
* Modifying histograms
* Heroes with histograms
* Recap of the rescue

# 02-Importing & Cleaning Data
Learn to import data from various sources, such as Excel, SQL, SAS, and right from the web. From there, learn to efficiently prepare and clean your data so it is ready to by analyzed.

## 02-01-Importing Data in Python (Part 1)
As a Data Scientist, on a daily basis you will need to clean data, wrangle and munge it, visualize it, build predictive models and interpret these models. Before doing any of these, however, you will need to know how to get data into Python. In this course, you'll learn the many ways to import data into Python: (i) from flat files such as .txts and .csvs; (ii) from files native to other software such as Excel spreadsheets, Stata, SAS and MATLAB files; (iii) from relational databases such as SQLite & PostgreSQL.

#### 02-01-01-[Introduction and flat files](</python/02-Importing & Cleaning Data/01-Importing Data in Python (Part 1)/01-Introduction and flat files>)
In this chapter, you'll learn how to import data into Python from all types of flat files, a simple and prevalent form of data storage. You've previously learned how to use NumPy and pandas - you will learn how to use these packages to import flat files, as well as how to customize your imports.

* Welcome to the course!
* Exploring your working directory
* Importing entire text files
* Importing text files line by line
* The importance of flat files in data science
* Pop quiz: examples of flat files
* Pop quiz: what exactly are flat files?
* Why we like flat files and the Zen of Python
* Importing flat files using NumPy
* Using NumPy to import flat files
* Customizing your NumPy import
* Importing different datatypes
* Working with mixed datatypes (1)
* Working with mixed datatypes (2)
* Importing flat files using pandas
* Using pandas to import flat files as DataFrames (1)
* Using pandas to import flat files as DataFrames (2)
* Customizing your pandas import
* Final thoughts on data import

#### 02-01-02-[Importing data from other file types](</python/02-Importing & Cleaning Data/01-Importing Data in Python (Part 1)/02-Importing data from other file types>)
You've learned how to import flat files, but there are many other file types you will potentially have to work with as a data scientist. In this chapter, you'll learn how to import data into Python from a wide array of important file types. You will be importing file types such as pickled files, Excel spreadsheets, SAS and Stata files, HDF5 files, a file type for storing large quantities of numerical data, and MATLAB files.

* Introduction to other file types
* Not so flat any more
* Loading a pickled file
* Listing sheets in Excel files
* Importing sheets from Excel files
* ~~Customizing your spreadsheet import~~
* Importing SAS/Stata files using pandas
* How to import SAS7BDAT
* Importing SAS files
* Using read_stata to import Stata files
* Importing Stata files
* Importing HDF5 files
* Using File to import HDF5 files
* Using h5py to import HDF5 files
* Extracting data from your HDF5 file
* Importing MATLAB files
* Loading .mat files
* The structure of .mat in Python

#### 02-01-03-[Working with relational databases in Python](</python/02-Importing & Cleaning Data/01-Importing Data in Python (Part 1)/03-Working with relational databases in Python>)
In this chapter, you'll learn how to extract meaningful data from relational databases, an essential element of any data scientist's toolkit. You will be learning about the relational model, creating SQL queries, filtering and ordering your SQL records, and advanced querying by JOINing database tables.

* Introduction to relational databases
* Pop quiz: The relational model
* Creating a database engine in Python
* Creating a database engine
* What are the tables in the database?
* Querying relational databases in Python
* The Hello World of SQL Queries!
* Customizing the Hello World of SQL Queries
* Filtering your database records using SQL's WHERE
* Ordering your SQL records with ORDER BY
* Querying relational databases directly with pandas
* Pandas and The Hello World of SQL Queries!
* Pandas for more complex querying
* Advanced Querying: exploiting table relationships
* The power of SQL lies in relationships between tables: INNER JOIN
* Filtering your INNER JOIN
* Final Thoughts

## 02-02-Importing Data in Python (Part 2)
As a Data Scientist, on a daily basis you will need to clean data, wrangle and munge it, visualize it, build predictive models and interpret these models. Before doing any of these, however, you will need to know how to get data into Python. In the prequel to this course, you have already learnt many ways to import data into Python: (i) from flat files such as .txts and .csvs; (ii) from files native to other software such as Excel spreadsheets, Stata, SAS and MATLAB files; (iii) from relational databases such as SQLite & PostgreSQL. In this course, you'll extend this knowledge base by learning to import data (i) from the web and (ii) a special and essential case of this: pulling data from Application Programming Interfaces, also known as APIs, such as the Twitter streaming API, which allows us to stream real-time tweets.

#### 02-02-01-[Importing data from the Internet](</python/02-Importing & Cleaning Data/02-Importing Data in Python (Part 2)/01-Importing data from the Internet>)
The web is a rich source of data from which you can extract various types of insights and findings. In this chapter, you will learn how to get data from the web, whether it be stored in files or in HTML. You'll also learn the basics of scraping and parsing web data.

* Importing flat files from the web
* Importing flat files from the web: your turn!
* Opening and reading flat files from the web
* Importing non-flat files from the web
* HTTP requests to import files from the web
* Performing HTTP requests in Python using urllib
* Printing HTTP request results in Python using urllib
* Performing HTTP requests in Python using requests
* Scraping the web in Python
* Parsing HTML with BeautifulSoup
* Turning a webpage into data using BeautifulSoup: getting the text
* Turning a webpage into data using BeautifulSoup: getting the hyperlinks

#### 02-02-02-[Interacting with APIs to import data from the web](</python/02-Importing & Cleaning Data/02-Importing Data in Python (Part 2)/02-Interacting with APIs to import data from the web>)
In this chapter, you will push further on your knowledge of importing data from the web. You will learn the basics of extracting data from APIs, gain insight on the importance of APIs and practice getting data from them with dives into the OMDB and Library of Congress APIs.

* Introduction to APIs and JSONs
* Pop quiz: What exactly is a JSON?
* Loading and exploring a JSON
* Pop quiz: Exploring your JSON
* APIs and interacting with the world wide web
* Pop quiz: What's an API?
* API requests
* JSON–from the web to Python
* Checking out the Wikipedia API

#### 02-02-03-[Diving deep into the Twitter API](</python/02-Importing & Cleaning Data/02-Importing Data in Python (Part 2)/03-Diving deep into the Twitter API>)
In this chapter, you will consolidate your knowledge of interacting with APIs in a deep dive into the Twitter streaming API. You'll learn how to stream real-time Twitter data and to analyze and visualize it!

* The Twitter API and Authentication
* API Authentication
* Streaming tweets
* Load and explore your Twitter data
* Twitter data to DataFrame
* A little bit of Twitter text analysis
* Plotting your Twitter data
* Final Thoughts

## 02-03-Cleaning Data in Python
A vital component of data science involves acquiring raw data and getting it into a form ready for analysis. In fact, it is commonly said that data scientists spend 80% of their time cleaning and manipulating data, and only 20% of their time actually analyzing it. This course will equip you with all the skills you need to clean your data in Python, from learning how to diagnose your data for problems to dealing with missing values and outliers. At the end of the course, you'll apply all of the techniques you've learned to a case study in which you'll clean a real-world Gapminder dataset!

#### 02-03-01-[Exploring your data](</python/02-Importing & Cleaning Data/03-Cleaning Data in Python/01-Exploring your data>)
So you've just got a brand new dataset and are itching to start exploring it. But where do you begin, and how can you be sure your dataset is clean? This chapter will introduce you to the world of data cleaning in Python! You'll learn how to explore your data with an eye for diagnosing issues such as outliers, missing values, and duplicate rows.

* Diagnose data for cleaning
* Loading and viewing your data
* Further diagnosis
* Exploratory data analysis
* Calculating summary statistics
* Frequency counts for categorical data
* Visual exploratory data analysis
* Visualizing single variables with histograms
* Visualizing multiple variables with boxplots
* Visualizing multiple variables with scatter plots

#### 02-03-02-[Tidying data for analysis](</python/02-Importing & Cleaning Data/03-Cleaning Data in Python/02-Tidying data for analysis>)
Here, you'll learn about the principles of tidy data and more importantly, why you should care about them and how they make subsequent data analysis more efficient. You'll gain first hand experience with reshaping and tidying your data using techniques such as pivoting and melting.

* Tidy data
* Recognizing tidy data
* Reshaping your data using melt
* Customizing melted data
* Pivoting data
* Pivot data
* Resetting the index of a DataFrame
* Pivoting duplicate values
* Beyond melt and pivot
* Splitting a column with .str
* Splitting a column with .split() and .get()

#### 02-03-03-[Combining data for analysis](</python/02-Importing & Cleaning Data/03-Cleaning Data in Python/03-Combining data for analysis>)
The ability to transform and combine your data is a crucial skill in data science, because your data may not always come in one monolithic file or table for you to load. A large dataset may be broken into separate datasets to facilitate easier storage and sharing. Or if you are dealing with time series data, for example, you may have a new dataset for each day. No matter the reason, it is important to be able to combine datasets so you can either clean a single dataset, or clean each dataset separately and then combine them later so you can run your analysis on a single dataset. In this chapter, you'll learn all about combining data.

* Concatenating data
* Combining rows of data
* Combining columns of data
* Finding and concatenating data
* Finding files that match a pattern
* Iterating and concatenating all matches
* Merge data
* 1-to-1 data merge
* Many-to-1 data merge
* Many-to-many data merge

#### 02-03-04-[Cleaning data for analysis](</python/02-Importing & Cleaning Data/03-Cleaning Data in Python/04-Cleaning data for analysis>)
Here, you'll dive into some of the grittier aspects of data cleaning. You'll learn about string manipulation and pattern matching to deal with unstructured data, and then explore techniques to deal with missing or duplicate data. You'll also learn the valuable skill of programmatically checking your data for consistency, which will give you confidence that your code is running correctly and that the results of your analysis are reliable!

* Data types
* Converting data types
* Working with numeric data
* Using regular expressions to clean strings
* String parsing with regular expressions
* Extracting numerical values from strings
* Pattern matching
* Using functions to clean data
* Custom functions to clean data
* Lambda functions
* Duplicate and missing data
* Dropping duplicate data
* Filling missing data
* Testing with asserts
* Testing your data with asserts

#### 02-03-05-[Case study](</python/02-Importing & Cleaning Data/03-Cleaning Data in Python/05-Case study>)
In this final chapter, you'll apply all of the data cleaning techniques you've learned in this course towards tidying a real-world, messy dataset obtained from the Gapminder Foundation. Once you're done, not only will you have a clean and tidy dataset, you'll also be ready to start working on your own data science projects using the power of Python!

* Putting it all together
* Exploratory analysis
* Visualizing your data
* Thinking about the question at hand
* Assembling your data
* Initial impressions of the data
* Reshaping your data
* Checking the data types
* Looking at country spellings
* More data cleaning and processing
* Wrapping up
* Final thoughts

# 03-Data Manipulation
Harness the power of tools such as pandas and SQLAlchemy so you can extract, filter, and transform your data quickly and efficiently.

## 03-01-Introduction to Databases
In this Python SQL course, you'll learn the basics of using Structured Query Language (SQL) with Python. This will be useful since whether you like it or not, databases are ubiquitous and, as a data scientist, you'll need to interact with them constantly. The Python SQL toolkit SQLAlchemy provides an accessible and intuitive way to query, build & write to SQLite, MySQL and Postgresql databases (among many others), all of which you will encounter in the daily life of a data scientist.

#### 03-01-01-[Basics of Relational Databases](</python/03-Data Manipulation/01-Introduction to Databases in Python/01-Basics of Relational Databases>)
In this chapter, you will become acquainted with the fundamentals of Relational Databases and the Relational Model. You will learn how to connect to a database and then interact with it by writing basic SQL queries, both in raw SQL as well as with SQLAlchemy, which provides a Pythonic way of interacting with databases.

* Introduction to Databases
* Relational Model
* Connecting to your Database
* Engines and Connection Strings
* Autoloading Tables from a Database
* Viewing Table Details
* Introduction to SQL
* Selecting data from a Table: raw SQL
* Selecting data from a Table with SQLAlchemy
* Handling a ResultSet
* Congratulations!

#### 03-01-02-[Applying Filtering, Ordering and Grouping to Queries](</python/03-Data Manipulation/01-Introduction to Databases in Python/02-Applying Filtering, Ordering and Grouping to Queries>)
In this chapter, you will build on the database knowledge you began acquiring in the previous chapter by writing more nuanced queries that allow you to filter, order, and count your data, all within the Pythonic framework provided by SQLAlchemy!

* Filtering and Targeting Data
* Connecting to a PostgreSQL Database
* Filter data selected from a Table - Simple
* Filter data selected from a Table - Expressions
* Filter data selected from a Table - Advanced
* Overview of Ordering
* Ordering by a Single Column
* Ordering in Descending Order by a Single Column
* Ordering by Multiple Columns
* Counting, Summing and Grouping Data
* Counting Distinct Data
* Count of Records by State
* Determining the Population Sum by State
* Let's use Pandas and Matplotlib to visualize our Data
* SQLAlchemy ResultsProxy and Pandas Dataframes
* From SQLAlchemy results to a Graph

#### 03-01-03-[Advanced SQLAlchemy Queries](</python/03-Data Manipulation/01-Introduction to Databases in Python/03-Advanced SQLAlchemy Queries>)
Herein, you will learn to perform advanced - and incredibly useful - queries that will enable you to interact with your data in powerful ways.

* Calculating Values in a Query
* Connecting to a MySQL Database
* Calculating a Difference between Two Columns
* Determining the Overall Percentage of Females
* SQL Relationships
* Automatic Joins with an Established Relationship
* Joins
* More Practice with Joins
* Working with Hierarchical Tables
* Using alias to handle same table joined queries
* Leveraging Functions and Group_bys with Hierarchical Data
* Dealing with Large ResultSets
* Working on Blocks of Records

#### 03-01-04-[Creating and Manipulating your own Databases](</python/03-Data Manipulation/01-Introduction to Databases in Python/04-Creating and Manipulating your own Databases>)
In the previous chapters, you interacted with existing databases and queried them in various different ways. Now, you will learn how to build your own databases and keep them updated!

* Creating Databases and Tables
* Creating Tables with SQLAlchemy
* Constraints and Data Defaults
* Inserting Data into a Table
* Inserting a single row with an insert() statement
* Inserting Multiple Records at Once
* Loading a CSV into a Table
* Updating Data in a Database
* Updating individual records
* Updating Multiple Records
* Correlated Updates
* Removing Data From a Database
* Deleting all the records from a table
* Deleting specific records
* Deleting a Table Completely

#### 03-01-05-[Putting it all together](</python/03-Data Manipulation/01-Introduction to Databases in Python/05-Putting it all together>)
Here, you will bring together all of the skills you acquired in the previous chapters to work on a real life project! From connecting to a database, to populating it, to reading and querying it, you will have a chance to apply all the key concepts you learned in this course. Enjoy!

* Census Case Study
* Setup the Engine and MetaData
* Create the Table to the Database
* Populating the Database
* Reading the Data from the CSV
* Load Data from a list into the Table
* Example Queries
* Build a Query to Determine the Average Age by Population
* Build a Query to Determine the Percentage of Population by Gender and State
* Build a Query to Determine the Difference by State from the 2000 and 2008 Censuses
* Congratulations
